# Athena PKMS Configuration
# Copy this file to .env and configure your settings

# ===== AI Provider Configuration =====
# Athena uses OpenAI-compatible endpoints, making it work with:
# - OpenAI directly
# - LiteLLM proxy
# - Azure OpenAI
# - Any OpenAI-compatible API

# Backend type (openai or anthropic)
GARDENER_BACKEND=openai

# Base URL for the AI API (default: OpenAI)
AI_BASE_URL=https://api.openai.com/v1

# API Key (AI_API_KEY takes precedence, falls back to OPENAI_API_KEY)
AI_API_KEY=sk-...
# OPENAI_API_KEY=sk-...  # Alternative if you prefer this name

# Model for complex tasks (classification, reasoning)
AI_MODEL_THINKING=gpt-4o

# Model for quick tasks (suggestions, refinement)
AI_MODEL_FAST=gpt-4o-mini

# Legacy fallback (used if AI_MODEL_THINKING is unset)
# AI_MODEL=gpt-4o

# Request timeout in seconds
AI_TIMEOUT=120

# ===== LiteLLM Example =====
# If using LiteLLM as a proxy:
# AI_BASE_URL=http://localhost:4000/v1
# AI_API_KEY=your-litellm-key
# AI_MODEL_FAST=claude-3-haiku-20240307
# AI_MODEL_THINKING=claude-3-5-sonnet-20241022

# ===== Ollama Example =====
# If using Ollama locally:
# AI_BASE_URL=http://localhost:11434/v1
# AI_API_KEY=ollama  # Ollama doesn't need a real key
# AI_MODEL_FAST=llama3.2
# AI_MODEL_THINKING=llama3.2

# ===== Data Directory =====
# Where the knowledge base is stored (used inside containers)
DATA_DIR=/data
